{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd03379e8676e9631a4a1e94b23c6f48e2a21e107e996b6372d116f44d0b3df3f41",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3379e8676e9631a4a1e94b23c6f48e2a21e107e996b6372d116f44d0b3df3f41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Transfer Learning - Part 2: Fine Tuning\n",
    "\n",
    "Feature Extraction vs Fine Tuning\n",
    "* Feature Extraction has a custom final layer trained on your data. All the underlying layers stay frozen.\n",
    "* Fine Tuning takes an existing model and unfreezes some of the layers. Fine tuning, usually requires more data than feature extraction.\n",
    "\n",
    "Things we'll do here:\n",
    "* Introduce fine tuning learning with tensorflow\n",
    "* Introduce the keras functional API to build models\n",
    "* Use a small dataset to experiment faster (10% of training samples)\n",
    "* Data Augmentation (making your training set more diverse without adding samples)\n",
    "* Running a series of experiments on our food vision data\n",
    "* Introduce the ModelCheckpoint callback to save intermediate training results\n",
    "\n",
    "\n",
    "Other Notes:\n",
    "* ImageNet has a wide variety of images we can train with\n",
    "* EfficientNet architecture already works well on computer vision tasks\n",
    "* We'll tune patterns/weights to our own problem\n",
    "* Model performs better than from scratch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import urllib.request\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers.tf_classification_helper_functions as helpers\n",
    "import imp\n",
    "imp.reload(helpers)\n",
    "helpers.show_environment()\n",
    "helpers.show_gpu_info()"
   ]
  },
  {
   "source": [
    "# Downloading the Data\n",
    "\n",
    "Get 10% of 10 food classes from food 101\n",
    "\n",
    "* The zip file we use in this notebook [is here](https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Setup variables for our data\n",
    "if os.name == \"nt\":\n",
    "    zip_download_file = \"c:/temp/data/10_food_classes_10_percent/10_food_classes_10_percent.zip\"\n",
    "    zip_extract_location = \"c:/temp/data/10_food_classes_10_percent/\"\n",
    "    data_dir = \"c:/temp/data/10_food_classes_10_percent/10_food_classes_10_percent\"\n",
    "else:\n",
    "    zip_download_file = \"/home/pi/Dev/data/10_food_classes_10_percent/10_food_classes_10_percent.zip\"\n",
    "    zip_extract_location = \"/home/pi/Dev/data/10_food_classes_10_percent/\"\n",
    "    data_dir = \"/home/pi/Dev/data/10_food_classes_10_percent/10_food_classes_10_percent\"\n",
    "\n",
    "train_data_dir = data_dir + \"/train\"\n",
    "test_data_dir = data_dir + \"/test\""
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the data set\n",
    "# TODO: UNCOMMENT ME if you havent downloaded it yet\n",
    "if not os.path.isfile(zip_download_file):\n",
    "    !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip -O $zip_download_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the data\n",
    "# Get the data set\n",
    "# TODO: UNCOMMENT ME if you havent downloaded and unzipped it yet\n",
    "if not os.path.exists(data_dir):\n",
    "    zip_ref = zipfile.ZipFile(zip_download_file)\n",
    "    zip_ref.extractall(path=zip_extract_location)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk through the data directory and list number of files\n",
    "helpers.walk_directory(data_dir)\n"
   ]
  },
  {
   "source": [
    "# 1. Visualize our Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = helpers.get_class_names_from_directory(data_dir+\"/train/\")\n",
    "print(class_names), len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a random image from the training data set\n",
    "helpers.view_random_images_from_directory (\n",
    "    directory = train_data_dir, \n",
    "    class_names = class_names,\n",
    "    #Optionally pass in a specific class to show only images from that class\n",
    "    #class_to_show = random.choice(class_names),\n",
    "    num_images=4,\n",
    "    figsize=(20,20)\n",
    ")"
   ]
  },
  {
   "source": [
    "# 2. Preprocess our Images\n",
    "\n",
    "Our next step is to turn our data into batches and load our training and test sets.\n",
    "\n",
    "A batch is a small subset of data. Rather than look at all ~10k images, a model might only look at 32 at a time. \n",
    "\n",
    "It does this for a couple of reasons:\n",
    "* 10k images might not fit into the memory of the procesor\n",
    "* Trying to learn the patterns in 10k images in one hit could result in the model not being able to learn very well.\n",
    "\n",
    "Why 32?\n",
    "\n",
    "Because 32 is good for your health per Yann Lecun. (google yann lecun batchsize, see his twitter post). Yann Lecun is a professor at NYU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# image_dataset_from_directory creates a tf.data.DataSet return type and is faster\n",
    "# than using ImageDataGenerator.flow_from_directory\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory (\n",
    "    directory=train_data_dir,\n",
    "    # Reshape all the images to be the same size. \n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode = \"categorical\", # categorical (2d one hot encoded labels) or binary\n",
    "    batch_size = BATCH_SIZE,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory (\n",
    "    directory=test_data_dir,\n",
    "    # Reshape all the images to be the same size. \n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode = \"categorical\", # categorical (2d one hot encoded labels) or binary\n",
    "    batch_size = BATCH_SIZE,\n",
    "    seed = 42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape is 224x224 image with 3 color channels, and then a 1 hot encoded label\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesnt work yet because when we normalize above we get a MapDataSet instead of a BatchDataset\n",
    "#train_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of train data batch\n",
    "# image_dataset_from_directory returns a BatchDataset. We have to call take in a for loop with the\n",
    "# number of batches to take\n",
    "for images, labels in train_data.take(1):\n",
    "    #len(images), len(labels)\n",
    "    #print(\"Took dataset\")\n",
    "    None # No-op\n",
    "\n",
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many batches are there\n",
    "len(train_data) # This equals 1500 images divided by batch size of 32, rounded up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.view_random_images_from_tf_dataset(dataset=train_data, class_names=class_names, batches=2, num_images=4, figsize=(10,10))"
   ]
  },
  {
   "source": [
    "# Model 0: Building a transfer learning feature extraction model using the Keras Functional API\n",
    "\n",
    "The sequential API is straight forward, it runs our layers in sequential order.\n",
    "But the funtional API gives us more flexibility with our models.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a base model with tf.keras.applications\n",
    "# The top layer has 1000 output neurons for the model trained on ImageNet. We want to\n",
    "# be able to specify that our model has a different number of outputs\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "# 2. Freeze the base model (so the underlying pre-trained patterns aren't updated during training)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create inputs into our model\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3),  name=\"input_layer\")\n",
    "\n",
    "# 4. If using a model like Resnet50V2 you will need to normalize inputs (you dont have to for efficient nets)\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "# 5. Pass the inputs to the base model\n",
    "x = base_model(inputs)\n",
    "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
    "\n",
    "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce the number of computations)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# 8. Combine the inputs with the outputs into a model\n",
    "model_0 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 9. Compile the Model\n",
    "model_0.compile (\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create a tensorboard callback\n",
    "tensorboard_callback = helpers.create_tensorboard_callback(\"c:/temp/data/05_tensorboard\", \"model_0\")\n",
    "\n",
    "#10. Fit the model and save its history\n",
    "history_0 = model_0.fit(\n",
    "    train_data,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    validation_data=test_data,\n",
    "    # We can tweak the number of validation steps if we want to try to speed it up by \n",
    "    # not validating on everything in the folder.\n",
    "    #validation_steps=len(test_data),\n",
    "    # Only validate on 25% of the test data\n",
    "    validation_steps=int(0.25 * len(test_data)),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on the full test dataset\r\n",
    "model_0.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the layers in our base model\n",
    "for layer_number, layer in enumerate(base_model.layers):\n",
    "    print(layer_number, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout the loss and accuracy of the model\n",
    "# If training loss is decreasing, but validation loss is increasing, then it shows our model is overfitting.\n",
    "# If the model is overfitting (learning the training data too well) it will get great results on the \n",
    "# training data, but it is failing to generalize well to unseen data and it performs poorly on the test data.\n",
    "imp.reload(helpers)\n",
    "helpers.plot_loss_curves(history_0)\n"
   ]
  },
  {
   "source": [
    "#Steak\n",
    "helpers.predict_and_plot_image(\n",
    "    model_0, \n",
    "    class_names = class_names,\n",
    "    url = \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\",\n",
    "    normalize_image=False)\n",
    "\n",
    "helpers.predict_and_plot_image(\n",
    "    model_0, \n",
    "    class_names = class_names,\n",
    "    url = \"https://hips.hearstapps.com/del.h-cdn.co/assets/18/08/1519155106-flank-steak-horizontal.jpg\",\n",
    "    normalize_image=False)\n",
    "\n",
    "#Curry\n",
    "#helpers.predict_and_plot_image(\n",
    "#    model_0, \n",
    "#    class_names = class_names,\n",
    "#    url = \"file:///c:/temp/data/10_food_classes_10_percent/10_food_classes_10_percent/test/chicken_curry/838.jpg\",\n",
    "#    normalize_image=False)\n",
    "\n",
    "#Pizza\n",
    "helpers.predict_and_plot_image(\n",
    "    model_0, \n",
    "    class_names = class_names,\n",
    "    url = \"https://upload.wikimedia.org/wikipedia/commons/1/10/Pepperoni_pizza.jpeg\",\n",
    "    normalize_image=False)\n",
    "\n",
    "\n",
    "#Curry\n",
    "helpers.predict_and_plot_image(\n",
    "    model_0, \n",
    "    class_names = class_names,\n",
    "    url = \"https://images.squarespace-cdn.com/content/v1/57bb2e8cb3db2b9076db6369/1529609506001-AI7Y83VYPGIFN3SVU7AB/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/AdobeStock_142271660.jpeg\",\n",
    "    normalize_image=False)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Getting a feature vector from a trained model - Learning Section\n",
    "\n",
    "A feature vector is a leaned representation of the input data (a compressed form of the input data based on how the model sees it)\n",
    "\n",
    "Lets demonstrate the global average pooling 2D layer.\n",
    "\n",
    "We have a tensor after our model goes through \"base model\" of shape (None, 7, 7, 1280).\n",
    "\n",
    "But then when it passes through GlobalAveragePooling2D, it turns in (None, 1280)\n",
    "\n",
    "Lets use a similar shaped tensor of (1, 4, 4, 3) and then pass it to GlobalAveragePooling2D."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (1, 4, 4, 3)\n",
    "\n",
    "# Create a random input tensor\n",
    "tf.random.set_seed(42)\n",
    "input_tensor = tf.random.normal(input_shape)\n",
    "print(f\"Random input tensor:\\n{input_tensor}\\n\")\n",
    "\n",
    "# Pass the random tensor through a GlobalAveragePooling2D layer\n",
    "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "print(f\"2D Global Average Pooled Random Tensor:\\n{global_average_pooled_tensor}\\n\")\n",
    "\n",
    "# Check the shape of the different tensors\n",
    "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
    "print(f\"Shape of Global Average Pooled tensor: {global_average_pooled_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets replicate the middle Global Average Pool 2D Layer\n",
    "# There are 4 axes in input_tensor (indexes 0-4), we are telling tensorflow to average it out across axes 1 and 2\n",
    "tf.reduce_mean(input_tensor, axis=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (1, 4, 4, 3)\n",
    "\n",
    "# Create a random input tensor\n",
    "tf.random.set_seed(42)\n",
    "input_tensor = tf.random.normal(input_shape)\n",
    "print(f\"Random input tensor:\\n{input_tensor}\\n\")\n",
    "\n",
    "# Pass the random tensor through a GlobalAveragePooling2D layer\n",
    "global_max_pooled_tensor = tf.keras.layers.GlobalMaxPooling2D()(input_tensor)\n",
    "print(f\"2D Global Max Pooled Random Tensor:\\n{global_max_pooled_tensor}\\n\")\n",
    "\n",
    "# Check the shape of the different tensors\n",
    "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
    "print(f\"Shape of Global Max Pooled tensor: {global_max_pooled_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what a global max pooled 2d logic does\n",
    "# There are 4 axes in input_tensor (indexes 0-4), we are telling tensorflow to take the max value across axes 1 and 2\n",
    "tf.reduce_max(input_tensor, axis=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just playing around here. Made a random tensor to emulate an image and see what the prediction is.\n",
    "# Create a random input tensor\n",
    "input_shape = (1, 224, 224, 3)\n",
    "tf.random.set_seed(100)\n",
    "input_tensor = tf.random.normal(input_shape)\n",
    "pred = model_0.predict(input_tensor)\n",
    "print(f\"Prediction:\\n{pred}\")\n",
    "print(f\"Index Highest Value in Prediction:\\n{np.argmax(pred)}\")\n",
    "print(f\"Predicted Class:\\n{class_names[np.argmax(pred)]}\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Running a series of transfer learning experiments\n",
    "\n",
    "We've seen the incredible results transfer learning can get with only 10% of the training data. But how does\n",
    "it go with only 1% of the training data. How about we setup a bunch of experiments to find out:\n",
    "\n",
    "* 1. model_1 - use feature extraction transfer learning with 1% of the training data with data augmentation\n",
    "* 2. model_2 - use feature extraction transfer learning with 10% of the training data with data augmentation\n",
    "* 3. model_3 - use fine tuning transfer learning on 10% of the training data with data augmentation\n",
    "* 4. model_4 - use fine tuning transfer learning on 100% of the training data with data augmentation\n",
    "\n",
    "Note: throughout all experiments the same test dataset will be used to evaluate our model. This ensures consistency across evaluation metrics.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == \"nt\":\n",
    "    zip_download_file_1_percent = \"c:/temp/data/10_food_classes_1_percent/10_food_classes_1_percent.zip\"\n",
    "    zip_extract_location_1_percent = \"c:/temp/data/10_food_classes_1_percent/\"\n",
    "    data_dir_1_percent = \"c:/temp/data/10_food_classes_1_percent/10_food_classes_1_percent\"\n",
    "\n",
    "    zip_download_file_all_data = \"c:/temp/data/10_food_classes_all_data/10_food_classes_all_data.zip\"\n",
    "    zip_extract_location_all_data = \"c:/temp/data/10_food_classes_all_data/\"\n",
    "    data_dir_all_data = \"c:/temp/data/10_food_classes_all_data/10_food_classes_all_data\"\n",
    "\n",
    "else:\n",
    "    zip_download_file_1_percent = \"/home/pi/Dev/data/10_food_classes_1_percent/10_food_classes_1_percent.zip\"\n",
    "    zip_extract_location_1_percent = \"/home/pi/Dev/data/10_food_classes_1_percent/\"\n",
    "    data_dir_1_percent = \"/home/pi/Dev/data/10_food_classes_1_percent/10_food_classes_1_percent\"\n",
    "\n",
    "    zip_download_file_all_data = \"/home/pi/Dev/data/10_food_classes_all_data/10_food_classes_all_data.zip\"\n",
    "    zip_extract_location_all_data = \"/home/pi/Dev/data/10_food_classes_all_data/\"\n",
    "    data_dir_all_data = \"/home/pi/Dev/data/10_food_classes_all_data/10_food_classes_all_data\"\n",
    "\n",
    "\n",
    "\n",
    "train_data_dir_1_percent = data_dir_1_percent + \"/train\"\n",
    "test_data_dir_1_percent = data_dir_1_percent + \"/test\"\n",
    "\n",
    "train_data_dir_all_data = data_dir_all_data + \"/train\"\n",
    "test_data_dir_all_data = data_dir_all_data + \"/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download and unzip data contain\n",
    "# Get the data set\n",
    "if not os.path.isfile(zip_download_file_1_percent):\n",
    "    !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip -O $zip_download_file_1_percent\n",
    "\n",
    "if not os.path.isfile(zip_download_file_all_data):\n",
    "    !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip -O $zip_download_file_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unzip the data\n",
    "# Get the data set\n",
    "# TODO: UNCOMMENT ME if you havent downloaded and unzipped it yet\n",
    "if not os.path.exists(data_dir_1_percent):\n",
    "    zip_ref = zipfile.ZipFile(zip_download_file_1_percent)\n",
    "    zip_ref.extractall(path=zip_extract_location_1_percent)\n",
    "    zip_ref.close()\n",
    "\n",
    "if not os.path.exists(data_dir_all_data):\n",
    "    zip_ref = zipfile.ZipFile(zip_download_file_all_data)\n",
    "    zip_ref.extractall(path=zip_extract_location_all_data)\n",
    "    zip_ref.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk through the data directory and list number of files\n",
    "helpers.walk_directory(data_dir_1_percent)\n",
    "print(\"\\n\\n\")\n",
    "helpers.walk_directory(data_dir_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a random image from the training data set\n",
    "helpers.view_random_images_from_directory (\n",
    "    directory = train_data_dir_1_percent, \n",
    "    class_names = class_names,\n",
    "    #Optionally pass in a specific class to show only images from that class\n",
    "    #class_to_show = random.choice(class_names),\n",
    "    num_images=4,\n",
    "    figsize=(20,20)\n",
    ")"
   ]
  },
  {
   "source": [
    "# model_1 - use feature extraction transfer learning with 1% of the training data with data augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Getting and preprocessing for model_1 - download and setup the data with 1% of the total dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# image_dataset_from_directory creates a tf.data.DataSet return type and is faster\n",
    "# than using ImageDataGenerator.flow_from_directory\n",
    "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory (\n",
    "    directory=train_data_dir_1_percent,\n",
    "    # Reshape all the images to be the same size. \n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode = \"categorical\", # categorical (2d one hot encoded labels) or binary\n",
    "    batch_size = BATCH_SIZE,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "test_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory (\n",
    "    directory=test_data_dir_1_percent,\n",
    "    # Reshape all the images to be the same size. \n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode = \"categorical\", # categorical (2d one hot encoded labels) or binary\n",
    "    batch_size = BATCH_SIZE,\n",
    "    seed = 42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.view_random_images_from_tf_dataset(dataset=train_data_1_percent, class_names=class_names, batches=2, num_images=4, figsize=(10,10))"
   ]
  },
  {
   "source": [
    "## Adding Data Augmentation right into the model\n",
    "\n",
    "To add data augmentation right into our models, we can use the layers inside:\n",
    "* tf.keras.layers.experimental.preprocessing()\n",
    "\n",
    "The benefits of using data augmentation right inside the model are:\n",
    "* Preprocessing the images (augmenting them) happens on the GPU (much faster) rather than the CPU\n",
    "* Image data augmentation only happens during training, so we can still export our whole model and use it elsewhere.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation stage with horizontal flipping, rotations, zooms, etc\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomWidth(0.2)\n",
    "    #tf.keras.layers.experimental.preprocessing.Rescaling(1./255) # Keep for models like Resnet50V2, but EfficientNets have rescaling built in\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.view_random_images_from_tf_dataset(dataset=train_data_1_percent, class_names=class_names, batches=1, num_images=6, figsize=(20,20), data_augmentation=data_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a base model with tf.keras.applications\n",
    "# The top layer has 1000 output neurons for the model trained on ImageNet. We want to\n",
    "# be able to specify that our model has a different number of outputs\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "# 2. Freeze the base model (so the underlying pre-trained patterns aren't updated during training)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create inputs into our model\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3),  name=\"input_layer\")\n",
    "\n",
    "# 4. Add in data augmentation sequential model as a layer\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# 5. Pass the inputs to the base model\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce the number of computations)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# 8. Combine the inputs with the outputs into a model\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 9. Compile the Model\n",
    "model_1.compile (\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create a tensorboard callback\n",
    "tensorboard_callback = helpers.create_tensorboard_callback(\"c:/temp/data/05_tensorboard\", \"model_1\")\n",
    "\n",
    "#10. Fit the model and save its history\n",
    "history_1 = model_1.fit(\n",
    "    train_data_1_percent,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(train_data_1_percent),\n",
    "    validation_data=test_data_1_percent,\n",
    "    # We can tweak the number of validation steps if we want to try to speed it up by \n",
    "    # not validating on everything in the folder.\n",
    "    #validation_steps=len(test_data),\n",
    "    # Only validate on 25% of the test data\n",
    "    validation_steps=int(0.25 * len(test_data_1_percent)),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout the loss and accuracy of the model\n",
    "# If training loss is decreasing, but validation loss is increasing, then it shows our model is overfitting.\n",
    "# If the model is overfitting (learning the training data too well) it will get great results on the \n",
    "# training data, but it is failing to generalize well to unseen data and it performs poorly on the test data.\n",
    "helpers.plot_loss_curves(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steak\n",
    "helpers.predict_and_plot_image(\n",
    "    model_1, \n",
    "    class_names = class_names,\n",
    "    url = \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\",\n",
    "    normalize_image=False)\n",
    "\n",
    "helpers.predict_and_plot_image(\n",
    "    model_1, \n",
    "    class_names = class_names,\n",
    "    url = \"https://hips.hearstapps.com/del.h-cdn.co/assets/18/08/1519155106-flank-steak-horizontal.jpg\",\n",
    "    normalize_image=False)\n",
    "\n",
    "#Curry\n",
    "helpers.predict_and_plot_image(\n",
    "    model_0, \n",
    "    class_names = class_names,\n",
    "    url = \"file:///c:/temp/data/10_food_classes_10_percent/10_food_classes_10_percent/test/chicken_curry/838.jpg\",\n",
    "    normalize_image=False)\n",
    "\n",
    "#Pizza\n",
    "helpers.predict_and_plot_image(\n",
    "    model_1, \n",
    "    class_names = class_names,\n",
    "    url = \"https://upload.wikimedia.org/wikipedia/commons/1/10/Pepperoni_pizza.jpeg\",\n",
    "    normalize_image=False)\n",
    "\n",
    "\n",
    "#Curry\n",
    "helpers.predict_and_plot_image(\n",
    "    model_1, \n",
    "    class_names = class_names,\n",
    "    url = \"https://images.squarespace-cdn.com/content/v1/57bb2e8cb3db2b9076db6369/1529609506001-AI7Y83VYPGIFN3SVU7AB/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/AdobeStock_142271660.jpeg\",\n",
    "    normalize_image=False)\n"
   ]
  },
  {
   "source": [
    "# model_2 - use feature extraction transfer learning with 10% of the training data with data augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation stage with horizontal flipping, rotations, zooms, etc\n",
    "# This is the same as above\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomWidth(0.2)\n",
    "    #tf.keras.layers.experimental.preprocessing.Rescaling(1./255) # Keep for models like Resnet50V2, but EfficientNets have rescaling built in\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "\n",
    "# 1. Create a base model with tf.keras.applications\n",
    "# The top layer has 1000 output neurons for the model trained on ImageNet. We want to\n",
    "# be able to specify that our model has a different number of outputs\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "# 2. Freeze the base model (so the underlying pre-trained patterns aren't updated during training)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create inputs into our model\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3),  name=\"input_layer\")\n",
    "\n",
    "# 4. Add in data augmentation sequential model as a layer\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# 5. Pass the inputs to the base model\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce the number of computations)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# 8. Combine the inputs with the outputs into a model\n",
    "model_2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 9. Compile the Model\n",
    "model_2.compile (\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Create a tensorboard callback\n",
    "tensorboard_callback = helpers.create_tensorboard_callback(\"c:/temp/data/05_tensorboard\", \"model_2\")\n",
    "#Create a Model Checkpoint callback\n",
    "checkpoint_callback = helpers.create_model_checkpoint_callback(\"c:/temp/data/checkpoints/05_model_2.ckpt\")\n",
    "\n",
    "initial_epochs = 5\n",
    "#10. Fit the model and save its history\n",
    "history_2 = model_2.fit(\n",
    "    train_data,\n",
    "    epochs=initial_epochs,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    validation_data=test_data,\n",
    "    # We can tweak the number of validation steps if we want to try to speed it up by \n",
    "    # not validating on everything in the folder.\n",
    "    #validation_steps=len(test_data),\n",
    "    # Only validate on 25% of the test data\n",
    "    validation_steps=int(0.25 * len(test_data)),\n",
    "    callbacks=[tensorboard_callback, checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What were model 0 results\n",
    "model_0.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model_2 results on all test data\n",
    "model_2_data_augmentation_results = model_2.evaluate(test_data)\n",
    "model_2_data_augmentation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout the loss and accuracy of the model\n",
    "# If training loss is decreasing, but validation loss is increasing, then it shows our model is overfitting.\n",
    "# If the model is overfitting (learning the training data too well) it will get great results on the \n",
    "# training data, but it is failing to generalize well to unseen data and it performs poorly on the test data.\n",
    "helpers.plot_loss_curves(history_2)"
   ]
  },
  {
   "source": [
    "# Loading in checkpointed weights\n",
    "Loading in checkpointed weights returns a model to a specific checkpointed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in saved model weights and evaluate model\n",
    "model_2.load_weights(\"c:/temp/data/checkpoints/05_model_2.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model_2 results on all test data\n",
    "model_2_loaded_weights_model_results = model_2.evaluate(test_data)\n",
    "model_2_loaded_weights_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_data_augmentation_results, model_2_loaded_weights_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(model_2_data_augmentation_results, model_2_loaded_weights_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the difference between the two results\n",
    "print(np.array(model_2_data_augmentation_results) - np.array(loaded_weights_model_results))"
   ]
  },
  {
   "source": [
    "# model_3 - use fine tuning transfer learning on 10% of the training data with data augmentation\n",
    "\n",
    "Fine tuning usally works best after training a feature extraction model for a few epochs with large amounts of custom data.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers in loaded model\n",
    "model_2.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are these layers trainable\n",
    "for i, layer in enumerate(model_2.layers):\n",
    "    print(i, layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Look at the layers within the efficient net v0 model and see if they are trainable\n",
    "for i, layer in enumerate(model_2.layers[2].layers):\n",
    "    print(i, layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many variables in the efficent net layer are trainable?\n",
    "print(len(model_2.layers[2].trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To begin fine tuning, lets start by setting the last 10 layers of our basemodel.trainable = True\n",
    "base_model.trainable = True\n",
    "# Set all layers except the last 10 layers trainable to false\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "# Recompile the model, we have to recompile every time we make a change\n",
    "model_2.compile (\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    # When fine tuning you typically want to lower the learning rate by 10x\n",
    "    # The Adam default LR is .001    \n",
    "    optimizer=tf.keras.optimizers.Adam(lr=.0001),\n",
    "    metrics=[\"accuracy\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are these layers trainable\n",
    "for i, layer in enumerate(model_2.layers):\n",
    "    print(i, layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Look at the layers within the efficient net v0 model and see if they are trainable\n",
    "#How many variables in the efficent net layer are trainable?\n",
    "print(len(model_2.layers[2].trainable_variables))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Show each layer and which are tunable\n",
    "for i, layer in enumerate(model_2.layers[2].layers):\n",
    "    print(i, layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many total variables in model 2 are trainable?\n",
    "print(len(model_2.trainable_variables))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune for another 5 epochs\n",
    "fine_tune_epochs = initial_epochs + 5\n",
    "\n",
    "# Create a tensorboard callback\n",
    "tensorboard_callback = helpers.create_tensorboard_callback(\"c:/temp/data/05_tensorboard\", \"model_3\")\n",
    "#Create a Model Checkpoint callback\n",
    "checkpoint_callback = helpers.create_model_checkpoint_callback(\"c:/temp/data/checkpoints/05_model_3.ckpt\")\n",
    "\n",
    "# Refit the model (same as model_2 except with more trainable layers)\n",
    "history_3 = model_2.fit(\n",
    "    train_data,\n",
    "    epochs=fine_tune_epochs,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    validation_data=test_data,\n",
    "    # We can tweak the number of validation steps if we want to try to speed it up by \n",
    "    # not validating on everything in the folder.\n",
    "    #validation_steps=len(test_data),\n",
    "    # Only validate on 25% of the test data\n",
    "    validation_steps=int(0.25 * len(test_data)),\n",
    "    # Because we already fit for 5 epochs, and we want to fine tune for another 5 epochs\n",
    "    initial_epoch=5,\n",
    "    callbacks=[tensorboard_callback, checkpoint_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fine tune model (model_3 which actually model_2 fine tuned for another 5 epochs\n",
    "model_3_results = model_2.evaluate(test_data)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout the loss and accuracy of the model\n",
    "# If training loss is decreasing, but validation loss is increasing, then it shows our model is overfitting.\n",
    "# If the model is overfitting (learning the training data too well) it will get great results on the \n",
    "# training data, but it is failing to generalize well to unseen data and it performs poorly on the test data.\n",
    "helpers.plot_loss_curves(history_3)"
   ]
  },
  {
   "source": [
    "The plot loss curves function works great with models which have only been fit once. However we want something to compare one series of running fit() with another (eg. before and after fine tuning)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.compare_loss_curves(history_2, history_3)"
   ]
  },
  {
   "source": [
    "# model_4 - use fine tuning transfer learning on 100% of the training data with data augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# ALL Data Work"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\r\n",
    "IMAGE_SIZE = (224, 224)\r\n",
    "BATCH_SIZE = 32\r\n",
    "\r\n",
    "# Set the seed for reproducibility\r\n",
    "tf.random.set_seed(42)\r\n",
    "\r\n",
    "# image_dataset_from_directory creates a tf.data.DataSet return type and is faster\r\n",
    "# than using ImageDataGenerator.flow_from_directory\r\n",
    "train_data_all_data = tf.keras.preprocessing.image_dataset_from_directory (\r\n",
    "    directory=train_data_dir_all_data,\r\n",
    "    # Reshape all the images to be the same size. \r\n",
    "    image_size=IMAGE_SIZE,\r\n",
    "    label_mode = \"categorical\", # categorical (2d one hot encoded labels) or binary\r\n",
    "    batch_size = BATCH_SIZE,\r\n",
    "    seed = 42\r\n",
    ")\r\n",
    "\r\n",
    "test_data_all_data = tf.keras.preprocessing.image_dataset_from_directory (\r\n",
    "    directory=test_data_dir_all_data,\r\n",
    "    # Reshape all the images to be the same size. \r\n",
    "    image_size=IMAGE_SIZE,\r\n",
    "    label_mode = \"categorical\", # categorical (2d one hot encoded labels) or binary\r\n",
    "    batch_size = BATCH_SIZE,\r\n",
    "    seed = 42\r\n",
    ")"
   ]
  },
  {
   "source": [
    "## Visualize our data augmentation layer (and see what happens to our data)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train a fine tuning model (model_4) we need to revert model_2 back to its feature extraction weights\n",
    "# Revert model 2 back to its feature extraction versions by loading its weights from checkpoint\n",
    "model_2.load_weights(\"c:/temp/data/checkpoints/05_model_2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets evaluate model_2 now\n",
    "model_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if our"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune for another 5 epochs\n",
    "fine_tune_epochs = initial_epochs + 5\n",
    "\n",
    "# Create a tensorboard callback\n",
    "tensorboard_callback = helpers.create_tensorboard_callback(\"c:/temp/data/05_tensorboard\", \"model_4\")\n",
    "#Create a Model Checkpoint callback\n",
    "checkpoint_callback = helpers.create_model_checkpoint_callback(\"c:/temp/data/checkpoints/05_model_4.ckpt\")\n",
    "\n",
    "# Recompile the model, we have to recompile every time we make a change\n",
    "model_2.compile (\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    # When fine tuning you typically want to lower the learning rate by 10x\n",
    "    # The Adam default LR is .001    \n",
    "    optimizer=tf.keras.optimizers.Adam(lr=.0001),\n",
    "    metrics=[\"accuracy\"]\n",
    ") \n",
    "\n",
    "fine_tune_epochs = initial_epochs + 5\n",
    "\n",
    "# Refit the model (same as model_2 except with more trainable layers)\n",
    "history_4 = model_2.fit(\n",
    "    train_data_all_data,\n",
    "    epochs=fine_tune_epochs,\n",
    "    steps_per_epoch=len(train_data_all_data),\n",
    "    validation_data=test_data_all_data,\n",
    "    # We can tweak the number of validation steps if we want to try to speed it up by \n",
    "    # not validating on everything in the folder.\n",
    "    #validation_steps=len(test_data),\n",
    "    # Only validate on 25% of the test data\n",
    "    validation_steps=int(0.25 * len(test_data_all_data)),\n",
    "    # Because we already fit for 5 epochs, and we want to fine tune for another 5 epochs\n",
    "    initial_epoch=5,\n",
    "    callbacks=[tensorboard_callback, checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_histories(history_2, history_4)"
   ]
  }
 ]
}